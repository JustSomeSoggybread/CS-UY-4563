{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 3 - Logistic Regression (50 points)\n",
    "\n",
    "\n",
    "## In this assignment:\n",
    "\n",
    "You'll employ gradient ascent to determine weights for a logistic regression problem focused on diagnosing breast cancer.\n",
    "\n",
    "### Dataset Overview:\n",
    "\n",
    "The **Breast Cancer Wisconsin dataset** is a widely-recognized collection of features manually recorded by physicians from fine needle aspiration samples. The primary objective is to determine whether the cells are benign or malignant based on these features. \n",
    "\n",
    "**Dataset details:** [Breast Cancer Wisconsin dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin)\n",
    "\n",
    "Each sample from the dataset is derived from a digitized image of a fine needle aspirate (FNA) of a breast mass. These images are processed to extract characteristics of cell nuclei, which are instrumental in the diagnostic process.\n",
    "\n",
    "### Features:\n",
    "\n",
    "The dataset consists of ten real-valued features that provide various measurements related to the cell nucleus:\n",
    "\n",
    "1. **Radius:** Mean of distances from the center to points on the perimeter.\n",
    "2. **Texture:** Standard deviation of gray-scale values.\n",
    "3. **Perimeter**\n",
    "4. **Area**\n",
    "5. **Smoothness:** Local variation in radius lengths.\n",
    "6. **Compactness:** \\( \\frac{\\text{perimeter}^2}{\\text{area}} - 1.0 \\)\n",
    "7. **Concavity:** Severity of concave portions of the contour.\n",
    "8. **Concave Points:** Number of concave portions of the contour.\n",
    "9. **Symmetry**\n",
    "10. **Fractal Dimension:** \"Coastline approximation\" - 1.\n",
    "\n",
    "### Task:\n",
    "\n",
    "Your mission is to use logistic regression on the provided features to predict whether a tumor is benign or malignant. Successfully doing so can greatly aid in early diagnosis, ultimately leading to saved lives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start\n",
    "\n",
    "For this semester, the teaching staff of this course will be using Autograder to grade programming assignment. Here are three things we would like you to know before starting. `PLEASE READ CAREFULLY.` Otherwise, you might lose points on some questions.\n",
    "\n",
    "* If you see any blocks containing statements like `grader.check(\"Qxx\")`, please `do not modify` them. You can add new cells to the notebook, but just make sure there is `no other cells` between the answer cells containing tag `# TODO Qxx` and grading cells like 'grader.check(\"Qxx\")`. \n",
    "\n",
    "* If the instructions say that you are required to use certain names for output variables, please `follow the instructions`, and you are not supposed to change the names of any given variables. You can still create new variables, but don't forget to `assign the output variables to correct values`. If the `type` of a output variable is specified, make sure the type of the variable is correct.\n",
    "\n",
    "* You can use print statements to print out results through out the notebook. However, if you have any `print statements within functions`, please make sure putting them `in comments` before you submit.\n",
    "\n",
    "* Please note for questions that require you to plot, please **_DO NOT MODIFY_** statements like `plt.show(block=False)`. Changing the statement would block the execution of autograder and you might lose points on that question.\n",
    "\n",
    "* Please `APPEND YOUR NYU NETID` to the name your submission (for example, name your submission as \"HW1_prog_abc12345.ipynb\" when you submit on Gradescope, and replace <abc1234> with your NYU NetID). \n",
    "\n",
    "Good luck with programming assignment 4!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Getting, preprocessing, and understanding the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the standard libraries\n",
    "\n",
    "### Essential Libraries\n",
    "\n",
    "- **NumPy**: A library for numerical operations in Python.\n",
    "- **Matplotlib**: Provides a way to visualize data.\n",
    "\n",
    "### Scikit-learn Utilities\n",
    "\n",
    "- **load_breast_cancer**: Dataset included in Scikit-learn for breast cancer classification.\n",
    "- **StandardScaler**: Part of Scikit-learn's preprocessing tools, used for standardizing features by removing the mean and scaling to unit variance.\n",
    "- **preprocessing**: Contains methods for preparing data before applying learning algorithms.\n",
    "- **train_test_split**: A utility function to split data into training and testing sets.\n",
    "- **LogisticRegression**: Module for implementing logistic regression, a method for binary classification\n",
    "\n",
    "> **Note**: Using the `%matplotlib inline` command ensures that Matplotlib visualizations are rendered directly within the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # importing Sklearn's logistic regression's module\n",
    "\n",
    "# Essential libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set up matplotlib for inline display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "\n",
    "In the below code cell, you will load the data from sklearn using the method given. Check import statements and use the given function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q01\n",
    "cancer = load_breast_cancer()   # type in load_breast_cancer()\n",
    "\n",
    "X = cancer.data  # type in cancer.data\n",
    "y = cancer.target  # type in cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "furnished-postage",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ01\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q01 - cancer.target.shape:  (569,)\n",
      "Q01 - cancer.data.shape:  (569, 30)\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - Print the shape of data and target\n",
    "print('Q01 - cancer.target.shape: ', y.shape)\n",
    "print('Q01 - cancer.data.shape: ', X.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# Read through the description of the dataset by uncommenting the line of code below\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "### Splitting the Data\n",
    "We divide our dataset into a training set and a testing set:\n",
    "- **Training Set**: 75%\n",
    "- **Testing Set**: 25%\n",
    "\n",
    "Use the `train_test_split` function to achieve this split:\n",
    "- Assign results to: `X_train`, `X_test`, `y_train`, `y_test`\n",
    "- Set `random_state` to 42 to ensure reproducibility.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scaling the Data Using Standard Scaler\n",
    "\n",
    "Since we are using gradient ascent, it's important to scale our data to ensure faster convergence. One of the most common methods to scale data is to use the `Standard Scaler`.\n",
    "\n",
    "The `Standard Scaler` normalizes the features by subtracting the mean and scaling to unit variance. \n",
    "\n",
    "Using `Standard Scaler`, each feature will have a mean of 0 and a standard deviation of 1 post-scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q02\n",
    "# Instantiate the `StandardScalar` object. Then fit the scalar object to the training data StandardScaler \n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(y_train.reshape(-1, 1))\n",
    "# scale both the traing and test data using the fitted scaler.\n",
    "\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "# Reshape `y_train` into 2D array, and `y_test` into 2D array \n",
    "y_2d_train = y_scaler.transform(y_train.reshape(-1, 1))\n",
    "y_2d_test = y_scaler.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expanded-hepatitis",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ02\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q02 - X_train.shape:  (426, 30)\n",
      "Q02 - y_2d_train.shape:  (426, 1)\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - Print the shape of X_train and y_2d_train\n",
    "print('Q02 - X_train.shape: ', X_train.shape)\n",
    "print('Q02 - y_2d_train.shape: ', y_2d_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q02 - cancer.feature_names:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - Printing the names of all the features\n",
    "print('Q02 - cancer.feature_names: ', cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a Bias Term to $X_{\\text{train}}$ and $X_{\\text{test}}$\n",
    "To account for the intercept term in our logistic regression model, we augment our feature matrices with a column of ones. This is often referred to as the bias term.\n",
    "\n",
    "Given our original matrix:\n",
    "$$X_{\\text{train}}=\\left[\\begin{matrix}\n",
    "x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\ddots & \\vdots \\\\\n",
    "x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "We add a column of ones:\n",
    "$$ X_{\\text{train}}=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots &\\ddots & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "Similarly, we augment $X_{\\text{test}}$ with a column of ones. This allows our algorithm to learn an intercept term without needing special handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainng data has dimensions:  (426, 31)\n",
      "[[ 1.         -0.34913849 -1.43851335 -0.41172595 -0.39047943 -1.86366229\n",
      "  -1.26860704 -0.82617052 -0.95286585 -1.72936805 -0.9415409  -0.86971355\n",
      "  -1.35865347 -0.83481506 -0.57230673 -0.74586846 -0.65398319 -0.52583524\n",
      "  -0.94677147 -0.53781728 -0.63449458 -0.54268486 -1.65565452 -0.58986401\n",
      "  -0.52555985 -1.51066925 -0.89149994 -0.75021715 -0.91671059 -0.92508585\n",
      "  -0.80841115]\n",
      " [ 1.         -0.20468665  0.31264011 -0.13367256 -0.27587995  1.07807258\n",
      "   0.86354605  0.72631375  0.89844062  1.17876963  1.47437716 -0.04022275\n",
      "  -0.50962253  0.10947722 -0.13472838 -0.52489487 -0.14934475  0.07460028\n",
      "   0.23747244 -0.43028253  0.08289146  0.04148684  0.68989862  0.19412774\n",
      "  -0.05193356  1.12941497  0.92394223  1.22221738  1.43655962  1.14955889\n",
      "   1.56911143]]\n"
     ]
    }
   ],
   "source": [
    "# TODO Q03\n",
    "# Appending a column of ones to X_train \n",
    "\n",
    "# Step 1: Create a column vector of ones (i.e. a vector of shape N',1)\n",
    "ones = np.ones((X_train.shape[0], 1))\n",
    "# Step 2: Append a column of ones in the beginning of X_train. Save in variable X_train_1(<np.ndarray>).\n",
    "X_train_1 = np.hstack((ones, X_train))\n",
    "\n",
    "\n",
    "# We can check that everything worked correctly by:\n",
    "# Printing out the new dimensions\n",
    "print(\"The trainng data has dimensions: \", X_train_1.shape)\n",
    "\n",
    "# Looking at the first two rows of X_train to check everything worked as expected\n",
    "print(X_train_1[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "empirical-species",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ03\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q03 - X_train_1.shape:  (426, 31)\n",
      "Q03 - X_train_1:  [[ 1.         -0.34913849 -1.43851335 ... -0.91671059 -0.92508585\n",
      "  -0.80841115]\n",
      " [ 1.         -0.20468665  0.31264011 ...  1.43655962  1.14955889\n",
      "   1.56911143]\n",
      " [ 1.         -0.32931176 -0.21507235 ... -0.7237126   0.53496977\n",
      "  -0.61934827]\n",
      " ...\n",
      " [ 1.          0.04739597 -0.56293662 ... -1.23262438 -0.68282718\n",
      "  -1.261137  ]\n",
      " [ 1.         -0.04040808  0.09966199 ...  1.08847951  0.48944465\n",
      "   1.26159953]\n",
      " [ 1.         -0.5502381   0.31264011 ... -0.59582424 -0.29911546\n",
      "  -0.82948141]]\n"
     ]
    }
   ],
   "source": [
    "# VERIFY\n",
    "print('Q03 - X_train_1.shape: ', X_train_1.shape)\n",
    "print('Q03 - X_train_1: ', X_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 2: Fitting the model\n",
    "\n",
    "## Implementing Logistic Regression Using Gradient Ascent\n",
    "\n",
    "\n",
    "You will perform the following steps:\n",
    "* write the sigmoid function $\\sigma(z)=\\frac{1}{1+e^{-z}}$\n",
    "* initialize ${\\bf w}$\n",
    "* prediction: write the function to compute the probability of every example in $X$ belonging to class one\n",
    "* write the log likelihood function (see lecture notes for the formula)\n",
    "* write the gradient ascent algorithm\n",
    "* plot the likelihood v/s the number of iterations\n",
    "* predict the class label (i.e. $0,1$) for every example in $X$ for a given ${\\bf w}$ and $t$\n",
    "* Evaluate your hypothesis by using your hypothesis to predict the label of the examples in the test set.  Using these predicted value you will then determine the precision, recall and F1 score of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid($z$)\n",
    "The first function you will write is sigmoid($z$)\n",
    "\n",
    "sigmoid($z$) takes as input a column vector of real numbers, $z^T = [z_1, z_2, ..., z_{N'}]$, where $N'$ is the number of  examples\n",
    "\n",
    "It should produce as output a column vector $\\left[\\frac{1}{1+e^{-z_1}},\\frac{1}{1+e^{-z_2}},...,\\frac{1}{1+e^{-z_{N'}}}\\right]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q04\n",
    "# Write the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fifty-tobacco",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ04\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q04 - sigmoid(0):  0.5\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - Sigmoid of 0 should be equal to half\n",
    "print('Q04 - sigmoid(0): ', sigmoid(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing ${\\bf w}$\n",
    "For testing the next functions, we create a coefficient vector, ${\\bf w}$.\n",
    "We will initialize the coeffients to be $0$, i.e. ${\\bf w}^T = [0,0,\\ldots ,0]$ (We could have initialized ${\\bf w}$ with any values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1)\n"
     ]
    }
   ],
   "source": [
    "# TODO Q05\n",
    "# Initialize w_init to a zero matrix with shape (X_train_1.shape[1],1)\n",
    "w_init = np.zeros((X_train_1.shape[1],1))\n",
    "##\n",
    "print(w_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "second-chile",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ05\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q05 - w_init.shape:  (31, 1)\n"
     ]
    }
   ],
   "source": [
    "# VERIFY|\n",
    "print('Q05 - w_init.shape: ', w_init.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Function\n",
    "Complete the `hypothesis` function to compute the probability that each example in \\(X\\) belongs to class one. Specifically, it calculates:\n",
    "\n",
    "$$\\hat{\\bf y}=\\sigma(X{\\bf w})$$\n",
    "\n",
    "For a single example represented by the design matrix:\n",
    "\n",
    "$$X=[1,x_1,x_2,\\ldots,x_d]$$\n",
    "\n",
    "and the corresponding weight vector:\n",
    "\n",
    "$${\\bf w}^T=[w_0,w_1,\\ldots, w_d]$$\n",
    "\n",
    "The function returns the logistic regression prediction:\n",
    "\n",
    "$$h({\\bf x})=\\frac{1}{1+e^{-\\left({w_{0}\\cdot 1 +w_1\\cdot x_1+\\cdots +w_d\\cdot x_d}\\right)}}$$\n",
    "\n",
    "Given a matrix with $N'$ examples:\n",
    "\n",
    "$$X=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots &\\ddots & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$$\n",
    "\n",
    "with the same weight vector, the function will return:\n",
    "\n",
    "$$[h({\\bf x}^{(1)}),h({\\bf x}^{(2)}),\\ldots, h({\\bf x}^{(N')})]^T$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q06\n",
    "# Write the hypothesis function which assumes the design matrix X is augmented with a column of ones\n",
    "def hypothesis(X, w):\n",
    "    return sigmoid(X.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "opposed-corps",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ06\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, do a quick check that your function can accept a matrix as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q07 \n",
    "# Compute y_hat(<np.ndarray>) using your hypotheis function with X_train_1 and w_init (w_init is still set to zero).  \n",
    "# This is just a preliminary test of the hypotheis function\n",
    "y_hat_init = hypothesis(X_train_1,w_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "received-outdoors",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ07\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q07 - y_hat_init:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n"
     ]
    }
   ],
   "source": [
    "# VERIFY\n",
    "print('Q07 - y_hat_init: ', y_hat_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Likelihood Function\n",
    "\n",
    "Write the function to calculate the log-likelihood:\n",
    "\n",
    "$$\n",
    "\\ell({\\bf w})= \\sum_{i=1}^{N'} y^{(i)} \\ln(h({\\bf x}^{(i)})) + (1 - y^{(i)}) \\ln(1 - h({\\bf x}^{(i)}))\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **Input**:\n",
    "  - Design matrix with $N'$ examples:\n",
    "    \n",
    "   $$\n",
    "    X = \\left[\\begin{array}{cccc}\n",
    "    1 & x^{(1)}_1 & \\ldots & x^{(1)}_d \\\\\n",
    "    1 & x^{(2)}_1 & \\ldots & x^{(2)}_d \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & x^{(N')}_1 & \\ldots & x^{(N')}_d \\\\\n",
    "    \\end{array}\\right]\n",
    "   $$\n",
    "    \n",
    "  - Column vector of labels for $X$:\n",
    "    \n",
    "  $$\n",
    "    {\\bf y}^T = [y^{(1)}, y^{(2)}, \\ldots, y^{(N')}]\n",
    "   $$\n",
    "  \n",
    "- **Output**:\n",
    "  - Log-likelihood value: $\\ell({\\bf w})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q08\n",
    "# Write the log likelihood function\n",
    "def log_likelihood(X, y, w):\n",
    " \n",
    "    h = hypothesis(X, w)\n",
    "    return np.sum((y * np.log(h)) + ((1 - y) * np.log(1 - h))) # you should return a real number, not a list containing a real number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "painful-punch",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ08\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, do a quick check of your log_likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q08 - likelihood:  -295.2806989185367\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - The value should be equal to -295.2806989185367 using X_train_1, y_2d_train, w, X_train_1.shape[0].\n",
    "print('Q08 - likelihood: ', log_likelihood(X_train_1, y_2d_train, w_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent\n",
    "Now write the code to perform gradient ascent.  You will use the update rule from the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q09\n",
    "# Write the gradient ascent function\n",
    "def Gradient_Ascent(X, y, learning_rate, num_iters, l):\n",
    "    # We assume X has been augmented with a column of ones\n",
    "    \n",
    "    # Number of training examples.\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Initialize w(<np.ndarray>). Zeros vector of shape X.shape[1],1\n",
    "    w = np.zeros((X.shape[1],1))\n",
    "    \n",
    "    # Initiating list to store values of likelihood(<list>) after few iterations.\n",
    "    log_likelihood_values = []\n",
    "    \n",
    "    # Gradient Ascent - local optimization technique\n",
    "    for i in range(num_iters):\n",
    "        w = w + ((learning_rate) * (((1/N) * (X.T).dot(y - hypothesis(X, w))) - (2 * l * w)) )\n",
    "        # Computing log likelihood of seeing examples for current value of w\n",
    "        if (i % 10) == 0:\n",
    "            log_likelihood_values.append(log_likelihood(X, y, w))\n",
    "            print(log_likelihood(X, y, w))\n",
    "        \n",
    "    return w, log_likelihood_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ancient-intensity",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ09\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-259.6228198668547\n",
      "7.345232229268328\n",
      "192.28226788373868\n",
      "343.94426690223713\n",
      "478.80798862460256\n",
      "603.9697998297171\n",
      "722.996570492698\n",
      "837.8777230688261\n",
      "949.809682899614\n",
      "1059.5542928796588\n",
      "1167.6189196226705\n",
      "1274.353891397649\n",
      "1380.008419875282\n",
      "1484.7642842784217\n",
      "1588.7569535727978\n",
      "1692.0892884302611\n",
      "1794.8406905182403\n",
      "1897.0733658763181\n",
      "1998.8367064798872\n",
      "2100.1704140761894\n",
      "2201.1067649800216\n",
      "2301.672276775923\n",
      "2401.8889514446614\n",
      "2501.775213894285\n",
      "2601.346628444151\n",
      "2700.616451358083\n",
      "2799.5960610369907\n",
      "2898.295295870318\n",
      "2996.722721709425\n",
      "3094.885845624478\n",
      "3192.791287854125\n",
      "3290.4449190969544\n",
      "3387.8519779576445\n",
      "3485.0171550661653\n",
      "3581.944684904821\n",
      "3678.63839662149\n",
      "3775.1017596548077\n",
      "3871.337956567715\n",
      "3967.349860696348\n",
      "4063.140297991379\n",
      "4158.711461610398\n",
      "4254.065580564985\n",
      "4349.205754061809\n",
      "4444.132950404943\n",
      "4538.847575283665\n",
      "4633.365178678598\n",
      "4727.671518087398\n",
      "4821.757758690035\n",
      "4915.593083838613\n",
      "5009.34252808955\n",
      "[[-2.71491224]\n",
      " [-1.8606299 ]\n",
      " [-1.17021861]\n",
      " [-1.8806343 ]\n",
      " [-1.81586179]\n",
      " [-0.88449195]\n",
      " [-1.26663627]\n",
      " [-1.6099876 ]\n",
      " [-1.94524907]\n",
      " [-0.79568064]\n",
      " [ 0.30820307]\n",
      " [-1.46443177]\n",
      " [-0.04987546]\n",
      " [-1.36752577]\n",
      " [-1.38630553]\n",
      " [ 0.15405115]\n",
      " [-0.36011649]\n",
      " [-0.28917061]\n",
      " [-0.76168758]\n",
      " [-0.00363232]\n",
      " [ 0.19398759]\n",
      " [-2.01425272]\n",
      " [-1.33453013]\n",
      " [-2.00391812]\n",
      " [-1.91126379]\n",
      " [-1.07773549]\n",
      " [-1.28223268]\n",
      " [-1.52598925]\n",
      " [-1.92923193]\n",
      " [-1.13004914]\n",
      " [-0.53010855]] [-259.6228198668547, 7.345232229268328, 192.28226788373868, 343.94426690223713, 478.80798862460256, 603.9697998297171, 722.996570492698, 837.8777230688261, 949.809682899614, 1059.5542928796588, 1167.6189196226705, 1274.353891397649, 1380.008419875282, 1484.7642842784217, 1588.7569535727978, 1692.0892884302611, 1794.8406905182403, 1897.0733658763181, 1998.8367064798872, 2100.1704140761894, 2201.1067649800216, 2301.672276775923, 2401.8889514446614, 2501.775213894285, 2601.346628444151, 2700.616451358083, 2799.5960610369907, 2898.295295870318, 2996.722721709425, 3094.885845624478, 3192.791287854125, 3290.4449190969544, 3387.8519779576445, 3485.0171550661653, 3581.944684904821, 3678.63839662149, 3775.1017596548077, 3871.337956567715, 3967.349860696348, 4063.140297991379, 4158.711461610398, 4254.065580564985, 4349.205754061809, 4444.132950404943, 4538.847575283665, 4633.365178678598, 4727.671518087398, 4821.757758690035, 4915.593083838613, 5009.34252808955]\n"
     ]
    }
   ],
   "source": [
    "# Please try many different values for the learning rate (including very small values).\n",
    "learning_rate = 0.01\n",
    "num_iters = 500\n",
    "# Calculate w and likelihood values using Gradient_Ascent with X_train_1, y_2d_train\n",
    "w, log_likelihood_values = Gradient_Ascent(X_train_1, y_2d_train, learning_rate, num_iters, 0.01)\n",
    "print(w, log_likelihood_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "upper-injection",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Likelihood v/s Number of Iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot Likelihood v/s Number of Iterations.\n",
    "iters = np.array(range(0,num_iters,10))\n",
    "plt.plot(iters,log_likelihood_values,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Log-Likelihood')\n",
    "plt.title(\"Log-Likelihood vs Number of Iterations.\")\n",
    "plt.grid()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the likelihood increasing as number of Iterations increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the class label for every example in $X$ for a given ${\\bf w}$ and $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Given a set of examples write the function to compute predicted which class for each example: 0 if the probability of belonging to class  is < t and returns 1 otherwise) - 10 points\n",
    "def predict_class(X, w, t):\n",
    "    classification = hypothesis(X, w)\n",
    "    return np.where(classification < t, 0, 1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "patient-breakdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ11\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, recall and F1: Evaluating your hypothesis using the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q12\n",
    "# Preidct the class y_hat using X_test and w you just calculated if the threshold is t = 0.5\n",
    "# First augment the test dataset with a column of ones.\n",
    "ones = np.ones((X_test.shape[0], 1))\n",
    "X_test_1 = np.hstack((ones, X_test))\n",
    "# Now predict the label of each example in your test set\n",
    "y_hat = predict_class(X_test_1, w, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mechanical-specific",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ12\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q13\n",
    "# Write the precision_recall function by first calculating: false_pos, false_neg and true_pos.  Using these numbers compute the precision and recall\n",
    "def precision_recall(y_hat, y, threshold):  \n",
    "    # Calculate false positive and false negative\n",
    "    # HINT: if done correctly, false_pos should be 1 and false_neg should be 1\n",
    "    false_pos = np.sum((y_hat == 1) & (y == 0))\n",
    "    false_neg = np.sum((y_hat == 0) & (y == 1))\n",
    "    print(\"false pos:\", false_pos)\n",
    "    print(\"false neg:\", false_neg)\n",
    "\n",
    "    # Calculate true positive and true negatives\n",
    "    # HINT: if done correctly, true_pos should be 88\n",
    "    true_pos = np.sum((y_hat == 1) & (y == 1))\n",
    "    print(\"true pos:\", true_pos)\n",
    "\n",
    "    precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "visible-earth",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false pos: 0\n",
      "false neg: 8\n",
      "true pos: 81\n",
      "Q14 - precision:  1.0\n",
      "Q14 - recall:  0.9101123595505618\n"
     ]
    }
   ],
   "source": [
    "# TODO Q14\n",
    "# Calculate precision and recall using on the test data where the threshold is 0.5\n",
    "\n",
    "precision, recall = precision_recall(y_hat, y_test, 0.5)\n",
    "\n",
    "print('Q14 - precision: ', precision)\n",
    "print('Q14 - recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "removable-copper",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ14\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q15\n",
    "# Write the F1_score function\n",
    "def f1_score(precision, recall):\n",
    "    return (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529411764705883"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the F1 score on the test data set using the precision and recall you computed above.\n",
    "f1_score(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "earlier-blast",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ15\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn's implementation of Logistic regression\n",
    "\n",
    "Next, use Sklearn's implementation of Logistic regression.  Once you have your hypothesis you will use your model on the test data and then evaluate how well it did using Sklearn's built in functions to compute the accuracy, precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model using Sklearn Library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Create object of logistic regression model. So we don't use any regularization, we can set the penalty to `none` or set C to a very large value (for example, C = 100000000), \n",
    "# to make lambda (C = 1/lambda) nearly 0.\n",
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "steady-plastic",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grader\u001b[38;5;241m.\u001b[39mcheck(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grader' is not defined"
     ]
    }
   ],
   "source": [
    "grader.check(\"Q16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Q17\n",
    "# Fit the model\n",
    "# Don't use matrix X_train_1. Instead, use X_train.\n",
    "logreg.fit(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-israeli",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: Q19\n",
    "manual: true\n",
    "points:\n",
    "  each: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q18\n",
    "# Print out all the coefficients\n",
    "w_logreg = logreg.coef_\n",
    "intercept_logreg = logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-trauma",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-noise",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q18 - w_logreg:  [[-0.39751679 -0.41535774 -0.34832129 -0.45142016 -0.20791905  0.62039231\n",
      "  -0.73558933 -1.09376305  0.23601875  0.08357971 -1.28501592  0.22136641\n",
      "  -0.58858571 -0.89527827 -0.19689721  0.63403697 -0.14135554 -0.40058728\n",
      "   0.5262862   0.73327971 -0.84378886 -1.29571675 -0.51790962 -0.82723207\n",
      "  -0.53895662  0.12288567 -1.00748469 -0.76642547 -1.21963558 -0.14580732]]\n",
      "Q18 - intercept_logreg:  [0.54105702]\n"
     ]
    }
   ],
   "source": [
    "# VERIFY - Compare the parameters computed by logreg model and gradient ascent. They should be nearly same.\n",
    "print('Q18 - w_logreg: ', w_logreg)\n",
    "print('Q18 - intercept_logreg: ', intercept_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measure: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q19 - Accuracy on training data = 0.979021\n"
     ]
    }
   ],
   "source": [
    "# TODO Q19\n",
    "# Find the predicted values on test set (X_test not X_test_1) using logreg.predict\n",
    "y_hat_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Find the accuracy achieved on test set using logreg.score and y_test \n",
    "acc_logreg = logreg.score(X_test, y_test)\n",
    "\n",
    "print(\"Q19 - Accuracy on training data = %f\" % acc_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-delight",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics: precision, recall, F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# TODO Q20\n",
    "# Find Precision, recall and fscore using precision_recall_fscore_support method of sklearn\n",
    "# Using y_test and y_hat_logreg\n",
    "prec, recal, fscore, sup = precision_recall_fscore_support(y_test, y_hat_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-dealer",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q20 - prec:  [0.96363636 0.98863636]\n",
      "Q20 - recal:  [0.98148148 0.97752809]\n",
      "Q20 - fscore:  [0.97247706 0.98305085]\n"
     ]
    }
   ],
   "source": [
    "# VERIFY\n",
    "print('Q20 - prec: ', prec)\n",
    "print('Q20 - recal: ', recal)\n",
    "print('Q20 - fscore: ', fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment!  Run your gradient ascent algorithm without scaling the training dataset.  \n",
    "What did you notice.  Describe the best hyperparamters  you found (i.e. `learning_rate`, and `num_iters`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Lambda: 0.3593813663804626\n",
      "Test Accuracy: 0.9790209790209791\n",
      "Training Accuracy: 0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "# 5.4 \n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "log_reg = linear_model.LogisticRegression(max_iter=1000, penalty='l2')\n",
    "param_grid = {'C': np.logspace(-4, 4, 10)}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=kf, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "optimal_C = grid_search.best_params_['C']\n",
    "optimal_lambda = 1 / optimal_C\n",
    "\n",
    "print(f\"Optimal Lambda:\", optimal_lambda)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_score}\")\n",
    "train_score=  best_model.score(X_test, y_test)\n",
    "print(f\"Training Accuracy: {train_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
